{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cekgyp_D4NtH",
        "outputId": "dbd6cda5-1887-45a0-a2e8-4a9e4ddf40f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sounddevice in /usr/local/lib/python3.12/dist-packages (0.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice) (2.23)\n"
          ]
        }
      ],
      "source": [
        "pip install sounddevice numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faster-whisper ffmpeg-python sentence-transformers faiss-cpu transformers torch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5RyBlZy93B9",
        "outputId": "a5bc156b-87a1-4064-c56b-39a7ac0cb490"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faster-whisper in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.12/dist-packages (0.2.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (4.6.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (0.36.0)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (0.22.1)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (1.23.2)\n",
            "Requirement already satisfied: av>=11 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (16.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (4.67.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.5)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (1.2.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (5.29.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper) (10.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt update\n",
        "!apt install -y ffmpeg\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehNKP3aR76RG",
        "outputId": "3626000f-80a2-4a60-a4ac-2ebc6c2d56c1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\u001b[0m\r                                                                               \rHit:2 https://cli.github.com/packages stable InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\u001b[0m\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connected\u001b[0m\r                                                                               \rHit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadconte\u001b[0m\r                                                                               \rHit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "54 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 54 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U ffmpeg-python openai-whisper faster-whisper pydub\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8eeq46j9G1n",
        "outputId": "5c4f030e-e073-460a-8aa4-75a80fa76c91"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.12/dist-packages (0.2.0)\n",
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.12/dist-packages (20250625)\n",
            "Requirement already satisfied: faster-whisper in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (0.25.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.9.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (3.5.0)\n",
            "Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (4.6.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (0.36.0)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (0.22.1)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (1.23.2)\n",
            "Requirement already satisfied: av>=11 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (16.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (75.2.0)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.12/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (2.32.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (1.2.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.14.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2025.11.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.11.1.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.21->faster-whisper) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.21->faster-whisper) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.21->faster-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.21->faster-whisper) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83PpiffW_bLN",
        "outputId": "26712188-441d-4f8a-8e6e-f6a42341159e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "libavutil      56. 70.100 / 56. 70.100\n",
            "libavcodec     58.134.100 / 58.134.100\n",
            "libavformat    58. 76.100 / 58. 76.100\n",
            "libavdevice    58. 13.100 / 58. 13.100\n",
            "libavfilter     7.110.100 /  7.110.100\n",
            "libswscale      5.  9.100 /  5.  9.100\n",
            "libswresample   3.  9.100 /  3.  9.100\n",
            "libpostproc    55.  9.100 / 55.  9.100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-community langchain-core langchain-text-splitters faiss-cpu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGNBVt5MaFCw",
        "outputId": "f7fd972b-3d99-4b3f-99d0-c4573eaedf1a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.2.6)\n",
            "Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.2)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.45)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.59)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.12.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.0)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.12.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -i input.mp4 -ar 16000 -ac 1 audio.wav\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hhEgpOM9T6h",
        "outputId": "dbf09492-c0a0-47ee-b29e-3a0623ac24d4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "\u001b[1;31minput.mp4: No such file or directory\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-huggingface\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3wiXzqFaFII",
        "outputId": "b4b72f8f-f600-4214-9ec2-220ac8963cc4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-huggingface in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.33.4 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (0.36.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (1.2.6)\n",
            "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (0.22.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2.32.5)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (1.2.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.4.59)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (2.12.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (9.1.2)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.12.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2025.11.12)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (4.12.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit faster-whisper faiss-cpu sentence-transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvMSFH-e_bTe",
        "outputId": "4cc550f8-c517-473f-b4a8-a63bfc7e8fea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.52.2)\n",
            "Requirement already satisfied: faster-whisper in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.2)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.4)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.5)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (4.6.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (0.36.0)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (0.22.1)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (1.23.2)\n",
            "Requirement already satisfied: av>=11 in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (16.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from faster-whisper) (4.67.1)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2.13.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (75.2.0)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.12/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper) (1.2.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (25.9.23)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.11.12)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.30.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper) (10.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"Hugging_face_API\"] = \"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\""
      ],
      "metadata": {
        "id": "sTbc5MNPeskJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "llm = pipeline(\n",
        "    \"text2text-generation\",\n",
        "    model=\"google/flan-t5-base\",\n",
        "    max_new_tokens=200\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y4CVaiiaORM",
        "outputId": "acb4951b-81ea-4c87-e2a0-decd5dbd7f41"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset everything related to previous video\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Delete FAISS index folder if saved\n",
        "if os.path.exists(\"faiss_index\"):\n",
        "    shutil.rmtree(\"faiss_index\")\n",
        "\n",
        "print(\" Old video data cleared\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwItDtBIG1XT",
        "outputId": "cfed2ab5-d679-49a2-f937-22e0313d4855"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Old video data cleared\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "from faster_whisper import WhisperModel\n",
        "import os\n",
        "\n",
        "# ------------------ PATHS ------------------\n",
        "VIDEO_PATH = \"/content/Feature Construction _ Feature Splitting.mp4\"\n",
        "#  CHANGE THIS TO YOUR ACTUAL VIDEO PATH"
      ],
      "metadata": {
        "id": "Qd18wdQpaEsd"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_audio(video_path, audio_path):\n",
        "    subprocess.run([\n",
        "        \"ffmpeg\", \"-y\",\n",
        "        \"-i\", video_path,\n",
        "        \"-ar\", \"16000\",\n",
        "        \"-ac\", \"1\",\n",
        "        audio_path\n",
        "    ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL,check=True)\n"
      ],
      "metadata": {
        "id": "7Q8vW39_aEvB"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "def build_faiss_index(chunks):\n",
        "    documents = [\n",
        "        Document(\n",
        "            page_content=c[\"text\"],\n",
        "            metadata={\"start\": c[\"start\"], \"end\": c[\"end\"]}\n",
        "        )\n",
        "        for c in chunks\n",
        "    ]\n",
        "    return FAISS.from_documents(documents, embedder)\n"
      ],
      "metadata": {
        "id": "S45ifnoqRTMV"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "def get_audio_path(video_path):\n",
        "    name = os.path.splitext(os.path.basename(video_path))[0]\n",
        "    name = name.replace(\" \", \"_\")\n",
        "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    return f\"audio_{name}_{ts}.wav\"\n"
      ],
      "metadata": {
        "id": "jVaA-KCJXzpR"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_new_video(video_path):\n",
        "    audio_path = get_audio_path(video_path)\n",
        "\n",
        "    print(\" Extracting audio...\")\n",
        "    extract_audio(video_path, audio_path)\n",
        "\n",
        "    if not os.path.exists(audio_path):\n",
        "        raise FileNotFoundError(f\"Audio extraction failed: {audio_path}\")\n",
        "\n",
        "    print(\" Transcribing...\")\n",
        "    transcript = transcribe_audio(audio_path)\n",
        "\n",
        "    print(\" Chunking...\")\n",
        "    chunks = chunk_transcript(transcript)\n",
        "\n",
        "    print(\" Building FAISS index...\")\n",
        "    index = build_faiss_index(chunks)\n",
        "\n",
        "    return transcript, chunks, index\n"
      ],
      "metadata": {
        "id": "3pl94raqu_OC"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from faster_whisper import WhisperModel\n",
        "whisper_model = WhisperModel(\"medium\", compute_type=\"int8\")\n"
      ],
      "metadata": {
        "id": "CXsXMLuDYkYI"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    segments, info = whisper_model.transcribe(audio_path, language=None)\n",
        "\n",
        "    transcript = []\n",
        "    for seg in segments:\n",
        "        transcript.append({\n",
        "            \"text\": seg.text.strip(),\n",
        "            \"start\": seg.start,\n",
        "            \"end\": seg.end\n",
        "        })\n",
        "\n",
        "    return transcript\n"
      ],
      "metadata": {
        "id": "jS9bAh2YaEx2"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------ RUN PIPELINE ------------------\n",
        "if not os.path.exists(VIDEO_PATH):\n",
        "    raise FileNotFoundError(f\"Video not found: {VIDEO_PATH}\")\n",
        "\n",
        "transcript, chunks, index = process_new_video(VIDEO_PATH)\n",
        "\n",
        "print(\"\\n===== TRANSCRIPT =====\\n\")\n",
        "print(transcript)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrGRAZ0PaE0s",
        "outputId": "f784e3d6-2385-4328-de2a-ba6796d98930"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Extracting audio...\n",
            " Transcribing...\n",
            " Chunking...\n",
            " Building FAISS index...\n",
            "\n",
            "===== TRANSCRIPT =====\n",
            "\n",
            "[{'text': 'hello guys welcome to my youtube channel', 'start': 0.0, 'end': 2.0}, {'text': '  feature engineering ', 'start': 2.0, 'end': 4.0}, {'text': '     ', 'start': 4.0, 'end': 6.0}, {'text': \"it's feature construction and feature splitting\", 'start': 6.0, 'end': 8.0}, {'text': \"so i'll share the screen\", 'start': 8.0, 'end': 10.0}, {'text': \"and let's discuss    \", 'start': 10.0, 'end': 12.0}, {'text': 'so if you remember', 'start': 12.0, 'end': 14.0}, {'text': '  feature engineering start  ', 'start': 14.0, 'end': 16.0}, {'text': '   ', 'start': 16.0, 'end': 18.0}, {'text': '- types   feature', 'start': 18.0, 'end': 20.0}, {'text': 'engineering   diagram', 'start': 20.0, 'end': 22.0}, {'text': '   ', 'start': 22.0, 'end': 24.0}, {'text': ' discuss    there are four', 'start': 24.0, 'end': 26.0}, {'text': 'types of feature engineering', 'start': 26.0, 'end': 28.0}, {'text': 'so there is feature transformation', 'start': 28.0, 'end': 30.0}, {'text': 'feature construction, feature selection', 'start': 30.0, 'end': 32.0}, {'text': 'and feature extraction', 'start': 32.0, 'end': 34.0}, {'text': 'so     ', 'start': 34.0, 'end': 36.0}, {'text': 'videos    ', 'start': 36.0, 'end': 38.0}, {'text': '  feature transformation', 'start': 38.0, 'end': 40.0}, {'text': '     ', 'start': 40.0, 'end': 42.0}, {'text': ' missing value imputation ', 'start': 42.0, 'end': 44.0}, {'text': 'categorical data  ', 'start': 44.0, 'end': 46.0}, {'text': 'handle    ', 'start': 46.0, 'end': 48.0}, {'text': 'outlier detection and removal ', 'start': 48.0, 'end': 50.0}, {'text': ' finally feature scaling  ', 'start': 50.0, 'end': 52.0}, {'text': '   feature transformation ', 'start': 52.0, 'end': 54.0}, {'text': '     topic ', 'start': 55.0, 'end': 57.0}, {'text': 'move    which is feature', 'start': 57.0, 'end': 59.0}, {'text': 'construction    ', 'start': 59.0, 'end': 61.0}, {'text': 'given feature  manually', 'start': 61.0, 'end': 63.0}, {'text': ' features   ', 'start': 63.0, 'end': 65.0}, {'text': '    ', 'start': 65.0, 'end': 67.0}, {'text': 'feature splitting  ', 'start': 67.0, 'end': 69.0}, {'text': '  already  features', 'start': 69.0, 'end': 71.0}, {'text': '  split    features', 'start': 71.0, 'end': 73.0}, {'text': '   ', 'start': 73.0, 'end': 75.0}, {'text': '  video  ', 'start': 75.0, 'end': 77.0}, {'text': '    topic  feature', 'start': 77.0, 'end': 79.0}, {'text': 'construction to be honest    video ', 'start': 79.0, 'end': 81.0}, {'text': 'cover   and then we will move on', 'start': 81.0, 'end': 83.0}, {'text': 'to this part feature', 'start': 83.0, 'end': 85.0}, {'text': 'extraction and feature selection', 'start': 85.0, 'end': 87.0}, {'text': '    videos ', 'start': 87.0, 'end': 89.0}, {'text': ' what I will do is I will', 'start': 89.0, 'end': 91.0}, {'text': 'move to the', 'start': 91.0, 'end': 93.0}, {'text': \"notebook for today's lecture\", 'start': 93.0, 'end': 95.0}, {'text': 'so what is feature construction', 'start': 95.0, 'end': 97.0}, {'text': 'feature construction', 'start': 97.0, 'end': 99.0}, {'text': 'is a', 'start': 99.0, 'end': 101.0}, {'text': 'very special kind of', 'start': 101.0, 'end': 103.0}, {'text': 'thing in feature engineering   ', 'start': 103.0, 'end': 105.0}, {'text': '   ', 'start': 105.0, 'end': 107.0}, {'text': '    ', 'start': 107.0, 'end': 109.0}, {'text': '       ', 'start': 109.0, 'end': 111.0}, {'text': 'feature construction is', 'start': 111.0, 'end': 113.0}, {'text': 'thoroughly manual   ', 'start': 113.0, 'end': 115.0}, {'text': '  there is no process', 'start': 115.0, 'end': 117.0}, {'text': '    ', 'start': 117.0, 'end': 119.0}, {'text': '  ', 'start': 119.0, 'end': 121.0}, {'text': ' features  create  ', 'start': 121.0, 'end': 123.0}, {'text': '    mathematical', 'start': 123.0, 'end': 125.0}, {'text': 'formula   ', 'start': 125.0, 'end': 127.0}, {'text': ' domain knowledge  basis ', 'start': 128.0, 'end': 130.0}, {'text': '   ', 'start': 130.0, 'end': 132.0}, {'text': '   ', 'start': 132.0, 'end': 134.0}, {'text': 'example  through  ', 'start': 134.0, 'end': 136.0}, {'text': 'I will be using the Titanic data set', 'start': 136.0, 'end': 138.0}, {'text': 'Titanic data set ', 'start': 138.0, 'end': 140.0}, {'text': 'What I will do is', 'start': 140.0, 'end': 142.0}, {'text': '   columns  ', 'start': 142.0, 'end': 144.0}, {'text': 'Sibling spouse', 'start': 144.0, 'end': 146.0}, {'text': 'and parent child', 'start': 146.0, 'end': 148.0}, {'text': '', 'start': 148.0, 'end': 149.0}, {'text': 'What I will do is', 'start': 149.0, 'end': 151.0}, {'text': '  columns  use ', 'start': 151.0, 'end': 153.0}, {'text': ' family type  ', 'start': 153.0, 'end': 155.0}, {'text': ' column ', 'start': 155.0, 'end': 157.0}, {'text': '  0, 1', 'start': 157.0, 'end': 159.0}, {'text': ' 2 values ', 'start': 159.0, 'end': 161.0}, {'text': '0  ', 'start': 161.0, 'end': 163.0}, {'text': '     ', 'start': 163.0, 'end': 165.0}, {'text': 'there is no family   ', 'start': 165.0, 'end': 167.0}, {'text': ' family ', 'start': 167.0, 'end': 169.0}, {'text': '        ', 'start': 169.0, 'end': 171.0}, {'text': \"it means it's a small family\", 'start': 171.0, 'end': 173.0}, {'text': \" 2   it's a large family\", 'start': 173.0, 'end': 175.0}, {'text': 'more than 4 people', 'start': 175.0, 'end': 177.0}, {'text': 'and I would also show you ', 'start': 177.0, 'end': 179.0}, {'text': '   feature construction ', 'start': 179.0, 'end': 181.0}, {'text': ' model   result ', 'start': 181.0, 'end': 183.0}, {'text': '     ', 'start': 183.0, 'end': 185.0}, {'text': \" again it's\", 'start': 185.0, 'end': 187.0}, {'text': 'very very dependent on', 'start': 187.0, 'end': 189.0}, {'text': 'that data that you are working upon', 'start': 189.0, 'end': 191.0}, {'text': '     ', 'start': 191.0, 'end': 193.0}, {'text': 'domain knowledge matter  ', 'start': 193.0, 'end': 195.0}, {'text': '      data ', 'start': 195.0, 'end': 197.0}, {'text': '   experience  ', 'start': 197.0, 'end': 199.0}, {'text': 'data scale    ', 'start': 199.0, 'end': 201.0}, {'text': 'feature construction  easy   ', 'start': 201.0, 'end': 203.0}, {'text': \"as a beginner it's quite difficult\", 'start': 203.0, 'end': 205.0}, {'text': '      ', 'start': 205.0, 'end': 207.0}, {'text': '  feature   feature  ', 'start': 207.0, 'end': 209.0}, {'text': '  ', 'start': 209.0, 'end': 211.0}, {'text': ' anyways       idea  ', 'start': 211.0, 'end': 213.0}, {'text': '   exist  ', 'start': 213.0, 'end': 215.0}, {'text': 'future      ', 'start': 215.0, 'end': 217.0}, {'text': 'can i use feature construction  ', 'start': 217.0, 'end': 219.0}, {'text': '   feature spitting  ', 'start': 219.0, 'end': 221.0}, {'text': '-    ', 'start': 221.0, 'end': 223.0}, {'text': ' same data ', 'start': 223.0, 'end': 225.0}, {'text': 'as in same column  ', 'start': 225.0, 'end': 227.0}, {'text': ' data  ', 'start': 227.0, 'end': 229.0}, {'text': ' tidy data  ', 'start': 229.0, 'end': 231.0}, {'text': 'so what do i mean by tidy data', 'start': 231.0, 'end': 233.0}, {'text': 'so tidy data    ', 'start': 233.0, 'end': 235.0}, {'text': '   observation', 'start': 235.0, 'end': 237.0}, {'text': ' row  ', 'start': 237.0, 'end': 239.0}, {'text': '  row   column ', 'start': 239.0, 'end': 241.0}, {'text': 'atomic values     ', 'start': 241.0, 'end': 243.0}, {'text': '      ', 'start': 243.0, 'end': 245.0}, {'text': ' -', 'start': 245.0, 'end': 247.0}, {'text': ' scenarios ', 'start': 247.0, 'end': 249.0}, {'text': '   data tidy  ', 'start': 249.0, 'end': 251.0}, {'text': '  single cell ', 'start': 251.0, 'end': 253.0}, {'text': '   data   ', 'start': 253.0, 'end': 255.0}, {'text': '  graphs     ', 'start': 255.0, 'end': 257.0}, {'text': ' easy  ', 'start': 257.0, 'end': 259.0}, {'text': '    scenarios ', 'start': 259.0, 'end': 261.0}, {'text': 'feature splitting  ', 'start': 261.0, 'end': 263.0}, {'text': ' 2-3 values  single cell      ', 'start': 263.0, 'end': 265.0}, {'text': 'I will give you one example', 'start': 265.0, 'end': 267.0}, {'text': 'Name column   Titanic ', 'start': 268.0, 'end': 271.0}, {'text': '    example ', 'start': 271.0, 'end': 273.0}, {'text': '    Mr. Ankit', 'start': 273.0, 'end': 275.0}, {'text': '   Mr. ', 'start': 275.0, 'end': 279.0}, {'text': ' salutation ', 'start': 279.0, 'end': 281.0}, {'text': ' Ankit    name ', 'start': 281.0, 'end': 283.0}, {'text': ' actually 2 pieces of information', 'start': 283.0, 'end': 285.0}, {'text': ' single cell  ', 'start': 285.0, 'end': 287.0}, {'text': '       columns  ', 'start': 287.0, 'end': 289.0}, {'text': '     Mr. word  ', 'start': 289.0, 'end': 291.0}, {'text': ' Mr. word       Ankit ', 'start': 291.0, 'end': 293.0}, {'text': 'And you would see', 'start': 293.0, 'end': 295.0}, {'text': '  salutation   ', 'start': 295.0, 'end': 297.0}, {'text': ' model  impact  ', 'start': 297.0, 'end': 299.0}, {'text': ' this is called feature splitting', 'start': 299.0, 'end': 301.0}, {'text': '     scenarios ', 'start': 301.0, 'end': 303.0}, {'text': ' help   ', 'start': 303.0, 'end': 305.0}, {'text': '    ', 'start': 305.0, 'end': 307.0}, {'text': '  quote    ', 'start': 307.0, 'end': 309.0}, {'text': '    ', 'start': 310.0, 'end': 312.0}, {'text': ' I will go back to', 'start': 312.0, 'end': 314.0}, {'text': 'Jupiter notebook', 'start': 314.0, 'end': 316.0}, {'text': '  imports   ', 'start': 316.0, 'end': 318.0}, {'text': 'This is my Titanic  data set', 'start': 318.0, 'end': 320.0}, {'text': '  columns import  ', 'start': 320.0, 'end': 322.0}, {'text': '   columns import  ', 'start': 322.0, 'end': 324.0}, {'text': '   input column', 'start': 324.0, 'end': 326.0}, {'text': '  survived ', 'start': 326.0, 'end': 328.0}, {'text': 'output column ', 'start': 328.0, 'end': 330.0}, {'text': '   ,   ', 'start': 330.0, 'end': 332.0}, {'text': 'feature construction  ', 'start': 332.0, 'end': 334.0}, {'text': '  simply  model  train  ', 'start': 334.0, 'end': 336.0}, {'text': '  model  ', 'start': 336.0, 'end': 338.0}, {'text': 'model  train   result ', 'start': 338.0, 'end': 340.0}, {'text': 'obviously    ', 'start': 340.0, 'end': 342.0}, {'text': '  age  missing data ', 'start': 342.0, 'end': 344.0}, {'text': '  data drop  ', 'start': 344.0, 'end': 346.0}, {'text': '  ', 'start': 346.0, 'end': 348.0}, {'text': ' x  y separate  ', 'start': 348.0, 'end': 350.0}, {'text': '   x', 'start': 350.0, 'end': 352.0}, {'text': ' ', 'start': 352.0, 'end': 354.0}, {'text': '  cross-val score ', 'start': 354.0, 'end': 356.0}, {'text': 'logistic regression algorithm ', 'start': 356.0, 'end': 358.0}, {'text': 'use   x  y ', 'start': 358.0, 'end': 360.0}, {'text': ' cross-validation 20 times ', 'start': 360.0, 'end': 362.0}, {'text': 'so this is the score that I am getting', 'start': 362.0, 'end': 364.0}, {'text': '69% accuracy', 'start': 364.0, 'end': 366.0}, {'text': '   feature construction ', 'start': 366.0, 'end': 368.0}, {'text': 'feature construction ', 'start': 368.0, 'end': 370.0}, {'text': 'what I am doing is', 'start': 370.0, 'end': 372.0}, {'text': '     columns  value ', 'start': 372.0, 'end': 374.0}, {'text': '   ', 'start': 374.0, 'end': 376.0}, {'text': 'column  family size ', 'start': 376.0, 'end': 378.0}, {'text': '  ', 'start': 378.0, 'end': 380.0}, {'text': '   columns   ', 'start': 380.0, 'end': 382.0}, {'text': ' plus one  add ', 'start': 382.0, 'end': 384.0}, {'text': '   family count ', 'start': 384.0, 'end': 386.0}, {'text': 'add  ', 'start': 386.0, 'end': 388.0}, {'text': '    column   family size', 'start': 388.0, 'end': 390.0}, {'text': 'so you can see this', 'start': 390.0, 'end': 392.0}, {'text': '   family size column', 'start': 392.0, 'end': 394.0}, {'text': '    ', 'start': 394.0, 'end': 396.0}, {'text': ' plus one ', 'start': 396.0, 'end': 398.0}, {'text': ' plus one    two  ', 'start': 398.0, 'end': 400.0}, {'text': '  ', 'start': 400.0, 'end': 402.0}, {'text': 'x  changes ', 'start': 402.0, 'end': 404.0}, {'text': '    function ', 'start': 404.0, 'end': 406.0}, {'text': '  conditionally   value return  ', 'start': 407.0, 'end': 410.0}, {'text': ' number  value one ', 'start': 410.0, 'end': 412.0}, {'text': '   travel   ', 'start': 412.0, 'end': 414.0}, {'text': 'I will return zero', 'start': 414.0, 'end': 416.0}, {'text': ' number  value is greater than one', 'start': 416.0, 'end': 418.0}, {'text': 'but less than equal to four', 'start': 418.0, 'end': 420.0}, {'text': '   small family ', 'start': 420.0, 'end': 422.0}, {'text': 'I will return one', 'start': 422.0, 'end': 424.0}, {'text': ' else    large family ', 'start': 424.0, 'end': 426.0}, {'text': 'I will return two', 'start': 426.0, 'end': 428.0}, {'text': '     ', 'start': 428.0, 'end': 430.0}, {'text': ' apply function  call ', 'start': 430.0, 'end': 432.0}, {'text': ' transformation  ', 'start': 432.0, 'end': 434.0}, {'text': ' ', 'start': 434.0, 'end': 436.0}, {'text': 'you can see ', 'start': 436.0, 'end': 438.0}, {'text': ' data  I have got these columns', 'start': 438.0, 'end': 440.0}, {'text': '  obviously  P class', 'start': 440.0, 'end': 442.0}, {'text': 'sibling spouse  family size', 'start': 442.0, 'end': 444.0}, {'text': '  columns    ', 'start': 444.0, 'end': 446.0}, {'text': ' what I will do is', 'start': 446.0, 'end': 448.0}, {'text': 'I will drop these three columns', 'start': 448.0, 'end': 450.0}, {'text': 'like this     ', 'start': 450.0, 'end': 452.0}, {'text': 'X head    ', 'start': 452.0, 'end': 454.0}, {'text': 'so I have got age, I have got', 'start': 454.0, 'end': 456.0}, {'text': 'P class and family type', 'start': 456.0, 'end': 458.0}, {'text': '    ', 'start': 458.0, 'end': 460.0}, {'text': 'same     cross', 'start': 460.0, 'end': 462.0}, {'text': ' logistic regression ', 'start': 462.0, 'end': 464.0}, {'text': ' and you can see', 'start': 464.0, 'end': 466.0}, {'text': '   accuracy   ', 'start': 466.0, 'end': 468.0}, {'text': '     ', 'start': 468.0, 'end': 470.0}, {'text': 'example    ', 'start': 470.0, 'end': 472.0}, {'text': '   feature construction', 'start': 472.0, 'end': 474.0}, {'text': 'can be useful   ', 'start': 474.0, 'end': 476.0}, {'text': '     data ', 'start': 476.0, 'end': 478.0}, {'text': 'project    ', 'start': 478.0, 'end': 480.0}, {'text': 'back of the mind   ', 'start': 480.0, 'end': 482.0}, {'text': 'can I use feature construction, can I create', 'start': 482.0, 'end': 484.0}, {'text': '    ', 'start': 484.0, 'end': 486.0}, {'text': 'feature in order to improve my', 'start': 486.0, 'end': 488.0}, {'text': 'accuracy     ', 'start': 488.0, 'end': 490.0}, {'text': 'example feature construction  now', 'start': 490.0, 'end': 492.0}, {'text': \"I'll move on to feature splitting\", 'start': 492.0, 'end': 494.0}, {'text': '  feature splitting   ', 'start': 494.0, 'end': 496.0}, {'text': ' Titanic  data ', 'start': 496.0, 'end': 498.0}, {'text': 'import    so this is the entire', 'start': 498.0, 'end': 500.0}, {'text': 'data   ', 'start': 500.0, 'end': 502.0}, {'text': 'focus      ', 'start': 502.0, 'end': 504.0}, {'text': 'column     name  column ', 'start': 504.0, 'end': 506.0}, {'text': 'focus  you would see', 'start': 506.0, 'end': 508.0}, {'text': '   ', 'start': 508.0, 'end': 510.0}, {'text': '      ', 'start': 510.0, 'end': 512.0}, {'text': '    ', 'start': 512.0, 'end': 514.0}, {'text': 'surname    ', 'start': 514.0, 'end': 516.0}, {'text': '     ', 'start': 516.0, 'end': 518.0}, {'text': '     ', 'start': 518.0, 'end': 520.0}, {'text': '     ', 'start': 520.0, 'end': 522.0}, {'text': 'Salutation    ', 'start': 522.0, 'end': 524.0}, {'text': '    code ', 'start': 524.0, 'end': 526.0}, {'text': '  name  ', 'start': 526.0, 'end': 528.0}, {'text': 'string   split ', 'start': 528.0, 'end': 530.0}, {'text': '   ', 'start': 530.0, 'end': 532.0}, {'text': '      ', 'start': 532.0, 'end': 534.0}, {'text': '    ,     ', 'start': 534.0, 'end': 536.0}, {'text': '    ', 'start': 536.0, 'end': 538.0}, {'text': ' ,      ', 'start': 538.0, 'end': 540.0}, {'text': '    ,     ', 'start': 541.0, 'end': 543.0}, {'text': '     ', 'start': 543.0, 'end': 545.0}, {'text': ' ', 'start': 545.0, 'end': 570.0}, {'text': 'See,  result , 0, 1,  2    ,       0 ,    Salutation  ,  Mr., Mrs., Miss,        ,      Column    ,    of title,    ,  ', 'start': 570.0, 'end': 600.0}, {'text': '     ,    ,  ', 'start': 600.0, 'end': 624.46}, {'text': '   ,      ', 'start': 624.46, 'end': 626.82}, {'text': '    ', 'start': 626.82, 'end': 628.82}, {'text': '     ,', 'start': 628.82, 'end': 630.82}, {'text': 'The Countess, MLLE   ,', 'start': 630.82, 'end': 632.82}, {'text': 'Spelling Mistake ,', 'start': 632.82, 'end': 634.82}, {'text': 'Lady, Miss,', 'start': 634.82, 'end': 636.82}, {'text': '      ,', 'start': 636.82, 'end': 638.82}, {'text': '   Misses, Miss,', 'start': 638.82, 'end': 640.82}, {'text': 'Master, Major,    ,', 'start': 640.82, 'end': 642.82}, {'text': '      ', 'start': 642.82, 'end': 644.82}, {'text': 'Misses,  Married Women ,', 'start': 644.82, 'end': 646.82}, {'text': '    ,', 'start': 646.82, 'end': 648.82}, {'text': 'Like 79% ,', 'start': 648.82, 'end': 650.82}, {'text': 'Similarly, Miss,', 'start': 650.82, 'end': 652.82}, {'text': '     ,', 'start': 652.82, 'end': 654.82}, {'text': '     ,', 'start': 654.82, 'end': 656.82}, {'text': '    ,', 'start': 656.82, 'end': 658.82}, {'text': '  70%', 'start': 658.82, 'end': 660.82}, {'text': '       ', 'start': 660.82, 'end': 662.82}, {'text': '   ,', 'start': 662.82, 'end': 664.82}, {'text': '       ,', 'start': 664.82, 'end': 666.82}, {'text': '    ,', 'start': 666.82, 'end': 668.82}, {'text': '  ,', 'start': 668.82, 'end': 669.82}, {'text': '    ,', 'start': 669.82, 'end': 671.82}, {'text': '      ,', 'start': 671.82, 'end': 673.82}, {'text': '      ,', 'start': 673.82, 'end': 675.82}, {'text': '       ,', 'start': 675.82, 'end': 677.82}, {'text': '    ,', 'start': 677.82, 'end': 679.82}, {'text': '     ,', 'start': 679.82, 'end': 681.82}, {'text': '        ,', 'start': 681.82, 'end': 683.82}, {'text': '        ,', 'start': 683.82, 'end': 685.82}, {'text': '          ,', 'start': 685.82, 'end': 689.82}, {'text': '         ,', 'start': 690.82, 'end': 693.82}, {'text': '     ,', 'start': 693.82, 'end': 695.82}, {'text': '         ,', 'start': 695.82, 'end': 698.82}, {'text': ' ,  ,', 'start': 698.82, 'end': 700.82}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_transcript(transcript, chunk_size=3):\n",
        "    chunks = []\n",
        "    for i in range(0, len(transcript), chunk_size):\n",
        "        group = transcript[i:i+chunk_size]\n",
        "        text = \" \".join([g[\"text\"] for g in group])\n",
        "        start = group[0][\"start\"]\n",
        "        end = group[-1][\"end\"]\n",
        "\n",
        "        chunks.append({\n",
        "            \"text\": text,\n",
        "            \"start\": start,\n",
        "            \"end\": end\n",
        "        })\n",
        "    return chunks\n"
      ],
      "metadata": {
        "id": "Cbtrm_oJaE3Z"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = chunk_transcript(transcript)\n"
      ],
      "metadata": {
        "id": "AIMSOZdoaE6S"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLE88Z0wofJy",
        "outputId": "583a9045-31eb-429b-b53c-126b6126e2ef"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': 'hello guys welcome to my youtube channel   feature engineering       ',\n",
              "  'start': 0.0,\n",
              "  'end': 6.0},\n",
              " {'text': \"it's feature construction and feature splitting so i'll share the screen and let's discuss    \",\n",
              "  'start': 6.0,\n",
              "  'end': 12.0},\n",
              " {'text': 'so if you remember   feature engineering start      ',\n",
              "  'start': 12.0,\n",
              "  'end': 18.0},\n",
              " {'text': '- types   feature engineering   diagram    ',\n",
              "  'start': 18.0,\n",
              "  'end': 24.0},\n",
              " {'text': ' discuss    there are four types of feature engineering so there is feature transformation',\n",
              "  'start': 24.0,\n",
              "  'end': 30.0},\n",
              " {'text': 'feature construction, feature selection and feature extraction so     ',\n",
              "  'start': 30.0,\n",
              "  'end': 36.0},\n",
              " {'text': 'videos       feature transformation      ',\n",
              "  'start': 36.0,\n",
              "  'end': 42.0},\n",
              " {'text': ' missing value imputation  categorical data   handle    ',\n",
              "  'start': 42.0,\n",
              "  'end': 48.0},\n",
              " {'text': 'outlier detection and removal   finally feature scaling      feature transformation ',\n",
              "  'start': 48.0,\n",
              "  'end': 54.0},\n",
              " {'text': '     topic  move    which is feature construction    ',\n",
              "  'start': 55.0,\n",
              "  'end': 61.0},\n",
              " {'text': 'given feature  manually  features        ',\n",
              "  'start': 61.0,\n",
              "  'end': 67.0},\n",
              " {'text': 'feature splitting     already  features   split    features',\n",
              "  'start': 67.0,\n",
              "  'end': 73.0},\n",
              " {'text': '      video       topic  feature',\n",
              "  'start': 73.0,\n",
              "  'end': 79.0},\n",
              " {'text': 'construction to be honest    video  cover   and then we will move on to this part feature',\n",
              "  'start': 79.0,\n",
              "  'end': 85.0},\n",
              " {'text': 'extraction and feature selection     videos   what I will do is I will',\n",
              "  'start': 85.0,\n",
              "  'end': 91.0},\n",
              " {'text': \"move to the notebook for today's lecture so what is feature construction\",\n",
              "  'start': 91.0,\n",
              "  'end': 97.0},\n",
              " {'text': 'feature construction is a very special kind of',\n",
              "  'start': 97.0,\n",
              "  'end': 103.0},\n",
              " {'text': 'thing in feature engineering            ',\n",
              "  'start': 103.0,\n",
              "  'end': 109.0},\n",
              " {'text': '        feature construction is thoroughly manual   ',\n",
              "  'start': 109.0,\n",
              "  'end': 115.0},\n",
              " {'text': '  there is no process        ',\n",
              "  'start': 115.0,\n",
              "  'end': 121.0},\n",
              " {'text': ' features  create       mathematical formula   ',\n",
              "  'start': 121.0,\n",
              "  'end': 127.0},\n",
              " {'text': ' domain knowledge  basis         ',\n",
              "  'start': 128.0,\n",
              "  'end': 134.0},\n",
              " {'text': 'example  through   I will be using the Titanic data set Titanic data set ',\n",
              "  'start': 134.0,\n",
              "  'end': 140.0},\n",
              " {'text': 'What I will do is    columns   Sibling spouse',\n",
              "  'start': 140.0,\n",
              "  'end': 146.0},\n",
              " {'text': 'and parent child  What I will do is',\n",
              "  'start': 146.0,\n",
              "  'end': 151.0},\n",
              " {'text': '  columns  use   family type    column ',\n",
              "  'start': 151.0,\n",
              "  'end': 157.0},\n",
              " {'text': '  0, 1  2 values  0  ',\n",
              "  'start': 157.0,\n",
              "  'end': 163.0},\n",
              " {'text': '      there is no family     family ',\n",
              "  'start': 163.0,\n",
              "  'end': 169.0},\n",
              " {'text': \"         it means it's a small family  2   it's a large family\",\n",
              "  'start': 169.0,\n",
              "  'end': 175.0},\n",
              " {'text': 'more than 4 people and I would also show you     feature construction ',\n",
              "  'start': 175.0,\n",
              "  'end': 181.0},\n",
              " {'text': \" model   result         again it's\",\n",
              "  'start': 181.0,\n",
              "  'end': 187.0},\n",
              " {'text': 'very very dependent on that data that you are working upon      ',\n",
              "  'start': 187.0,\n",
              "  'end': 193.0},\n",
              " {'text': 'domain knowledge matter         data     experience  ',\n",
              "  'start': 193.0,\n",
              "  'end': 199.0},\n",
              " {'text': \"data scale     feature construction  easy    as a beginner it's quite difficult\",\n",
              "  'start': 199.0,\n",
              "  'end': 205.0},\n",
              " {'text': '         feature   feature     ',\n",
              "  'start': 205.0,\n",
              "  'end': 211.0},\n",
              " {'text': ' anyways       idea      exist   future      ',\n",
              "  'start': 211.0,\n",
              "  'end': 217.0},\n",
              " {'text': 'can i use feature construction      feature spitting   -    ',\n",
              "  'start': 217.0,\n",
              "  'end': 223.0},\n",
              " {'text': ' same data  as in same column    data  ',\n",
              "  'start': 223.0,\n",
              "  'end': 229.0},\n",
              " {'text': ' tidy data   so what do i mean by tidy data so tidy data    ',\n",
              "  'start': 229.0,\n",
              "  'end': 235.0},\n",
              " {'text': '   observation  row     row   column ',\n",
              "  'start': 235.0,\n",
              "  'end': 241.0},\n",
              " {'text': 'atomic values              -',\n",
              "  'start': 241.0,\n",
              "  'end': 247.0},\n",
              " {'text': ' scenarios     data tidy     single cell ',\n",
              "  'start': 247.0,\n",
              "  'end': 253.0},\n",
              " {'text': '   data      graphs       easy  ',\n",
              "  'start': 253.0,\n",
              "  'end': 259.0},\n",
              " {'text': '    scenarios  feature splitting    2-3 values  single cell      ',\n",
              "  'start': 259.0,\n",
              "  'end': 265.0},\n",
              " {'text': 'I will give you one example Name column   Titanic      example ',\n",
              "  'start': 265.0,\n",
              "  'end': 273.0},\n",
              " {'text': '    Mr. Ankit    Mr.   salutation ',\n",
              "  'start': 273.0,\n",
              "  'end': 281.0},\n",
              " {'text': ' Ankit    name   actually 2 pieces of information  single cell  ',\n",
              "  'start': 281.0,\n",
              "  'end': 287.0},\n",
              " {'text': '       columns        Mr. word    Mr. word       Ankit ',\n",
              "  'start': 287.0,\n",
              "  'end': 293.0},\n",
              " {'text': 'And you would see   salutation     model  impact  ',\n",
              "  'start': 293.0,\n",
              "  'end': 299.0},\n",
              " {'text': ' this is called feature splitting      scenarios   help   ',\n",
              "  'start': 299.0,\n",
              "  'end': 305.0},\n",
              " {'text': '       quote         ',\n",
              "  'start': 305.0,\n",
              "  'end': 312.0},\n",
              " {'text': ' I will go back to Jupiter notebook   imports   ',\n",
              "  'start': 312.0,\n",
              "  'end': 318.0},\n",
              " {'text': 'This is my Titanic  data set   columns import      columns import  ',\n",
              "  'start': 318.0,\n",
              "  'end': 324.0},\n",
              " {'text': '   input column   survived  output column ',\n",
              "  'start': 324.0,\n",
              "  'end': 330.0},\n",
              " {'text': '   ,    feature construction     simply  model  train  ',\n",
              "  'start': 330.0,\n",
              "  'end': 336.0},\n",
              " {'text': '  model   model  train   result  obviously    ',\n",
              "  'start': 336.0,\n",
              "  'end': 342.0},\n",
              " {'text': '  age  missing data    data drop     ',\n",
              "  'start': 342.0,\n",
              "  'end': 348.0},\n",
              " {'text': ' x  y separate      x  ',\n",
              "  'start': 348.0,\n",
              "  'end': 354.0},\n",
              " {'text': '  cross-val score  logistic regression algorithm  use   x  y ',\n",
              "  'start': 354.0,\n",
              "  'end': 360.0},\n",
              " {'text': ' cross-validation 20 times  so this is the score that I am getting 69% accuracy',\n",
              "  'start': 360.0,\n",
              "  'end': 366.0},\n",
              " {'text': '   feature construction  feature construction  what I am doing is',\n",
              "  'start': 366.0,\n",
              "  'end': 372.0},\n",
              " {'text': '     columns  value      column  family size ',\n",
              "  'start': 372.0,\n",
              "  'end': 378.0},\n",
              " {'text': '      columns     plus one  add ',\n",
              "  'start': 378.0,\n",
              "  'end': 384.0},\n",
              " {'text': '   family count  add       column   family size',\n",
              "  'start': 384.0,\n",
              "  'end': 390.0},\n",
              " {'text': 'so you can see this    family size column     ',\n",
              "  'start': 390.0,\n",
              "  'end': 396.0},\n",
              " {'text': ' plus one   plus one    two     ',\n",
              "  'start': 396.0,\n",
              "  'end': 402.0},\n",
              " {'text': 'x  changes      function    conditionally   value return  ',\n",
              "  'start': 402.0,\n",
              "  'end': 410.0},\n",
              " {'text': ' number  value one     travel    I will return zero',\n",
              "  'start': 410.0,\n",
              "  'end': 416.0},\n",
              " {'text': ' number  value is greater than one but less than equal to four    small family ',\n",
              "  'start': 416.0,\n",
              "  'end': 422.0},\n",
              " {'text': 'I will return one  else    large family  I will return two',\n",
              "  'start': 422.0,\n",
              "  'end': 428.0},\n",
              " {'text': '       apply function  call   transformation  ',\n",
              "  'start': 428.0,\n",
              "  'end': 434.0},\n",
              " {'text': '  you can see   data  I have got these columns',\n",
              "  'start': 434.0,\n",
              "  'end': 440.0},\n",
              " {'text': '  obviously  P class sibling spouse  family size   columns    ',\n",
              "  'start': 440.0,\n",
              "  'end': 446.0},\n",
              " {'text': ' what I will do is I will drop these three columns like this     ',\n",
              "  'start': 446.0,\n",
              "  'end': 452.0},\n",
              " {'text': 'X head     so I have got age, I have got P class and family type',\n",
              "  'start': 452.0,\n",
              "  'end': 458.0},\n",
              " {'text': '     same     cross  logistic regression ',\n",
              "  'start': 458.0,\n",
              "  'end': 464.0},\n",
              " {'text': ' and you can see    accuracy         ',\n",
              "  'start': 464.0,\n",
              "  'end': 470.0},\n",
              " {'text': 'example        feature construction can be useful   ',\n",
              "  'start': 470.0,\n",
              "  'end': 476.0},\n",
              " {'text': '     data  project     back of the mind   ',\n",
              "  'start': 476.0,\n",
              "  'end': 482.0},\n",
              " {'text': 'can I use feature construction, can I create      feature in order to improve my',\n",
              "  'start': 482.0,\n",
              "  'end': 488.0},\n",
              " {'text': \"accuracy      example feature construction  now I'll move on to feature splitting\",\n",
              "  'start': 488.0,\n",
              "  'end': 494.0},\n",
              " {'text': '  feature splitting     Titanic  data  import    so this is the entire',\n",
              "  'start': 494.0,\n",
              "  'end': 500.0},\n",
              " {'text': 'data    focus       column     name  column ',\n",
              "  'start': 500.0,\n",
              "  'end': 506.0},\n",
              " {'text': 'focus  you would see           ',\n",
              "  'start': 506.0,\n",
              "  'end': 512.0},\n",
              " {'text': '     surname          ',\n",
              "  'start': 512.0,\n",
              "  'end': 518.0},\n",
              " {'text': '            Salutation    ',\n",
              "  'start': 518.0,\n",
              "  'end': 524.0},\n",
              " {'text': '    code    name   string   split ',\n",
              "  'start': 524.0,\n",
              "  'end': 530.0},\n",
              " {'text': '               ,     ',\n",
              "  'start': 530.0,\n",
              "  'end': 536.0},\n",
              " {'text': '      ,           ,     ',\n",
              "  'start': 536.0,\n",
              "  'end': 543.0},\n",
              " {'text': '        See,  result , 0, 1,  2    ,       0 ,    Salutation  ,  Mr., Mrs., Miss,        ,      Column    ,    of title,    ,  ',\n",
              "  'start': 543.0,\n",
              "  'end': 600.0},\n",
              " {'text': '     ,    ,      ,           ',\n",
              "  'start': 600.0,\n",
              "  'end': 628.82},\n",
              " {'text': '     , The Countess, MLLE   , Spelling Mistake ,',\n",
              "  'start': 628.82,\n",
              "  'end': 634.82},\n",
              " {'text': 'Lady, Miss,       ,    Misses, Miss,',\n",
              "  'start': 634.82,\n",
              "  'end': 640.82},\n",
              " {'text': 'Master, Major,    ,        Misses,  Married Women ,',\n",
              "  'start': 640.82,\n",
              "  'end': 646.82},\n",
              " {'text': '    , Like 79% , Similarly, Miss,',\n",
              "  'start': 646.82,\n",
              "  'end': 652.82},\n",
              " {'text': '     ,      ,     ,',\n",
              "  'start': 652.82,\n",
              "  'end': 658.82},\n",
              " {'text': '  70%            ,',\n",
              "  'start': 658.82,\n",
              "  'end': 664.82},\n",
              " {'text': '       ,     ,   ,',\n",
              "  'start': 664.82,\n",
              "  'end': 669.82},\n",
              " {'text': '    ,       ,       ,',\n",
              "  'start': 669.82,\n",
              "  'end': 675.82},\n",
              " {'text': '       ,     ,      ,',\n",
              "  'start': 675.82,\n",
              "  'end': 681.82},\n",
              " {'text': '        ,         ,           ,',\n",
              "  'start': 681.82,\n",
              "  'end': 689.82},\n",
              " {'text': '         ,      ,          ,',\n",
              "  'start': 690.82,\n",
              "  'end': 698.82},\n",
              " {'text': ' ,  ,', 'start': 698.82, 'end': 700.82}]"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "embedder = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        ")\n",
        "\n",
        "\n",
        "texts = [c[\"text\"] for c in chunks]\n",
        "embeddings = embedder.embed_documents(texts)\n",
        "\n",
        "\n",
        "dim = len(embeddings[0])\n",
        "index = faiss.IndexFlatL2(dim)\n",
        "index.add(np.array(embeddings))\n"
      ],
      "metadata": {
        "id": "IbGAimHkaE9N"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_question(query, index, chunks, embedder, k=3, threshold=0.7):\n",
        "    query_emb = embedder.embed_query(query)\n",
        "    query_emb = np.array([query_emb])  # FAISS expects 2D\n",
        "\n",
        "    distances, indices = index.search(query_emb, k)\n",
        "\n",
        "    results = []\n",
        "    for dist, idx in zip(distances[0], indices[0]):\n",
        "        similarity = 1 / (1 + dist)\n",
        "\n",
        "        if similarity >= threshold:\n",
        "            results.append({\n",
        "                \"text\": chunks[idx][\"text\"],\n",
        "                \"start\": chunks[idx][\"start\"],\n",
        "                \"end\": chunks[idx][\"end\"],\n",
        "                \"similarity\": similarity\n",
        "            })\n",
        "\n",
        "    return results\n",
        "\n"
      ],
      "metadata": {
        "id": "0eGHi7yOaFLu"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(query, retrieved_chunks):\n",
        "    context = \"\\n\".join([c[\"text\"] for c in retrieved_chunks])\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Answer the question using ONLY the context.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{query}\n",
        "\"\"\"\n",
        "\n",
        "    return llm(prompt)[0][\"generated_text\"]\n"
      ],
      "metadata": {
        "id": "MdQJpkqFi2XP"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_video(chunks):\n",
        "    full_text = \" \".join([c[\"text\"] for c in chunks])\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Summarize the following video transcript clearly:\n",
        "\n",
        "{full_text}\n",
        "\"\"\"\n",
        "\n",
        "    return llm(prompt)[0][\"generated_text\"]\n"
      ],
      "metadata": {
        "id": "8EJBwdMngQO2"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"HF_TOKEN\"] = \"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\"\n"
      ],
      "metadata": {
        "id": "c477jGy9Zynd"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"topic about feature Engineering is explained ? and summarize it ?\"\n",
        "\n",
        "retrieved = ask_question(\n",
        "    query=query,\n",
        "    index=index,\n",
        "    chunks=chunks,\n",
        "    embedder=embedder,\n",
        "    k=3,\n",
        "    threshold=0.5\n",
        ")\n",
        "\n",
        "if len(retrieved) == 0:\n",
        "    print(\"Sorry, No such content is discussed\")\n",
        "else:\n",
        "    answer = generate_answer(query, retrieved)\n",
        "\n",
        "    print(\"\\n Answer:\")\n",
        "    print(answer)\n",
        "\n",
        "    print(\"\\n Retrieved Text:\")\n",
        "    for r in retrieved:\n",
        "        print(r[\"text\"])\n",
        "\n",
        "    print(\"\\n Timestamps:\")\n",
        "    for r in retrieved:\n",
        "        print(f\"{r['start']:.1f}s  {r['end']:.1f}s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sYapofYga0K",
        "outputId": "ae3725c5-ff50-46d0-8ed8-5d554926f5c2"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Answer:\n",
            "feature construction is a very special kind of move to the notebook for today's lecture so what is feature construction  discuss     there are four types of feature engineering so there is feature transformation\n",
            "\n",
            " Retrieved Text:\n",
            "feature construction is a very special kind of\n",
            "move to the notebook for today's lecture so what is feature construction\n",
            " discuss    there are four types of feature engineering so there is feature transformation\n",
            "\n",
            " Timestamps:\n",
            "97.0s  103.0s\n",
            "91.0s  97.0s\n",
            "24.0s  30.0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NxWXpSSeb7pz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}